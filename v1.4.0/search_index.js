var documenterSearchIndex = {"docs":
[{"location":"api/problems/#Problems","page":"Problems","title":"Problems","text":"CurveFit defines two primary problem types: CurveFitProblem and NonlinearCurveFitProblem.  These types encapsulate the data to be fitted, along with optional model definitions and initial parameter guesses. The data and the initial guess are subtypes of AbstractArray.\n\nA CurveFitProblem represents a general curve fitting problem and requires only input data x and output data y. When no model is specified, both x and y must be one-dimensional arrays.\n\nNonlinearCurveFitProblem is a convenience constructor for defining nonlinear fitting problems. It returns a CurveFitProblem object with a user-provided model function  and an initial guess u0 for the model parameters. The model is supplied as a standard  Julia function and is internally wrapped as a NonlinearFunction. For details, see the  documentation for NonlinearFunction. If the output data y is not provided, it is treated as a zero vector.","category":"section"},{"location":"api/problems/#Constructors","page":"Problems","title":"Constructors","text":"","category":"section"},{"location":"api/problems/#Scalar-models","page":"Problems","title":"Scalar models","text":"For convenience when creating a model CurveFit provides a helper ScalarModel type that allows defining scalar models.","category":"section"},{"location":"api/problems/#CurveFit.CurveFitProblem","page":"Problems","title":"CurveFit.CurveFitProblem","text":"CurveFitProblem(x, y; nlfunc=nothing, u0=nothing, sigma=nothing)\n\nRepresents a curve fitting problem where x and y are the data points to fit.\n\nCertain algorithms may require an initial guess u0 for the coefficients to fit. See specific solver documentation for more details.\n\nWeights can be passed through sigma, which should be an array with the same dimensions as y. As with curve_fit() from scipy, the elements should be the standard deviation of y. Note that currently sigma is not supported for all kinds of fits, check the problem or algorithm docstring to see if sigma is supported.\n\nSee also NonlinearCurveFitProblem.\n\n\n\n\n\n","category":"type"},{"location":"api/problems/#CurveFit.NonlinearCurveFitProblem","page":"Problems","title":"CurveFit.NonlinearCurveFitProblem","text":"NonlinearCurveFitProblem(f, u0, x, y=nothing, sigma=nothing)\n\nNonlinear curve fitting problem where f is a nonlinear function to fit, u0 is the initial guess for the coefficients, x and y are the data points to fit, and sigma is the standard deviation associated with y. The following optimization problem is solved:\n\nargmin_u  left f(u x) - y right_2\n\nIf y is nothing, then it is treated as a zero vector. f is a generic Julia function or ideally a NonlinearFunction from SciMLBase.jl.\n\nFunction Signature\n\nThe model function f should have the signature f(params, x) where:\n\nparams is a vector of parameters to be fitted\nx is the input data (can be a vector or matrix)\n\nThe function should return predictions for all input data points. For vectorized operations over arrays, use Julia's broadcasting syntax with the @. macro:\n\n# Vectorized function using @.\nfn(a, x) = @. a[1] + a[2] * x^a[3]\n\nFor users who prefer to define scalar functions (e.g., those migrating from LsqFit.jl), use the ScalarModel wrapper:\n\n# Scalar function (operates on single x value)\nfn_scalar(a, x) = a[1] + a[2] * x^a[3]\nprob = NonlinearCurveFitProblem(ScalarModel(fn_scalar), u0, x, y)\n\nSee also ScalarModel.\n\n\n\n\n\n","category":"function"},{"location":"api/problems/#CurveFit.ScalarModel","page":"Problems","title":"CurveFit.ScalarModel","text":"ScalarModel(f)\n\nWraps a scalar function f(params, x_i) that operates on a single data point x_i into a vectorized form suitable for CurveFit.jl.\n\nThis is useful for users migrating from LsqFit.jl or those who prefer defining scalar model functions without explicit broadcasting via the @. macro.\n\nWhy is @. Typically Required?\n\nIn CurveFit.jl, model functions receive the entire data array x at once and must return predictions for all data points. This vectorized design enables:\n\nBetter GPU performance when using GPU arrays\nMore efficient compilation with tools like Reactant.jl\nUser control over array types\n\nUsing ScalarModel\n\nInstead of writing a vectorized function:\n\n# Vectorized function (uses @.)\nfn(a, x) = @. a[1] + a[2] * x^a[3]\nprob = NonlinearCurveFitProblem(fn, u0, x, y)\n\nYou can write a simpler scalar function:\n\n# Scalar function (no @. needed)\nfn_scalar(a, x) = a[1] + a[2] * x^a[3]\nprob = NonlinearCurveFitProblem(ScalarModel(fn_scalar), u0, x, y)\n\nMigration from LsqFit.jl\n\nFor users coming from LsqFit.jl, note that the parameter order is reversed:\n\nLsqFit.jl: model(x, p) (data first, then parameters)\nCurveFit.jl: model(p, x) (parameters first, then data)\n\nExample migration:\n\n# LsqFit.jl style (does NOT work directly)\nlsqfit_model(x, p) = p[1] * exp(-x * p[2])\n\n# CurveFit.jl with ScalarModel\ncurvefit_model(p, x) = p[1] * exp(-x * p[2])\nprob = NonlinearCurveFitProblem(ScalarModel(curvefit_model), u0, x, y)\n\n\n\n\n\n","category":"type"},{"location":"tutorials/stats/#StatsAPI-interface-usage","page":"StatsAPI interface usage","title":"StatsAPI interface usage","text":"This tutorial goes over basic functionality of the StatsAPI.jl interface as implemented by CurveFit. Solvers find coefficients of the model so that it fits the data as best as it can. Statistical tools allow user to assess how good and reliable their fitting result is. \n\nAfter solving a curve fitting problem (does not have to be a nonlinear problem), you can use statistical functions on the CurveFitSolution object. See StatsAPI functions to view all the implemented functions.","category":"section"},{"location":"tutorials/stats/#Examples","page":"StatsAPI interface usage","title":"Examples","text":"using CurveFit\n\nx = collect(1.0:10.0)\nθ_true = [3.0, 2.0, 1.5]\n\nf(θ, x) = @. θ[1] + θ[2] * x + x^θ[3]\ny = f(θ_true, x)\n\nprob = NonlinearCurveFitProblem(f, [1.0, 1.0, 1.0], x, y)\nsol = solve(prob)\n\n# Get the confidence intervals\nconfint(sol)","category":"section"},{"location":"tutorials/stats/#Basic-quantities","page":"StatsAPI interface usage","title":"Basic quantities","text":"residuals() measure the difference between the fitted model and the data.\nThe residual sum of squares (rss()) and mean squared error (mse()) summarize the overall fit quality.\nThe number of observations (nobs()) corresponds to the size of the data set used, i.e the number of data points.\npredict() gives a prediction using the fitted coefficients and new data. If only the solution object is passed, original data will be used in calculation.\nisconverged() checks if the solver was successful in solving the problem.\n\nSee StatsAPI functions to view all the implemented functions.","category":"section"},{"location":"tutorials/stats/#Parameter-uncertainty","page":"StatsAPI interface usage","title":"Parameter uncertainty","text":"CurveFit exposes parameter uncertainty through standard errors and covariance matrices. The covariance matrix estimates the joint uncertainty of the fitted coefficients under standard least squares assumptions. The diagonal entries correspond to the variance of each coefficient estimate, while the off-diagonal entries quantify correlations between coefficients. Standard errors are obtained as the square roots of the diagonal variances.","category":"section"},{"location":"tutorials/stats/#Confidence-intervals","page":"StatsAPI interface usage","title":"Confidence intervals","text":"Point estimates alone do not convey how uncertain a fitted coefficient is. Confidence intervals provide a range of values that are statistically consistent with the observed data under standard modelling assumptions.\n\nConfidence intervals can be computed with confint().","category":"section"},{"location":"tutorials/stats/#Interpreting-confidence-intervals","page":"StatsAPI interface usage","title":"Interpreting confidence intervals","text":"A 95% confidence interval means that, under repeated experiments with the same data-generating process, approximately 95% of such intervals would contain the true coefficient value.\n\nNarrow intervals indicate well-determined coefficients, while wide intervals suggest that the data provide limited information about a coefficient.\n\nConfidence intervals are commonly used to assess the reliability of the fitted coefficients.","category":"section"},{"location":"_changelog/#Changelog","page":"Changelog","title":"Changelog","text":"This documents notable changes in CurveFit.jl. The format is based on Keep a Changelog.","category":"section"},{"location":"_changelog/#[v1.4.0]-2026-01-31","page":"Changelog","title":"[v1.4.0] - 2026-01-31","text":"","category":"section"},{"location":"_changelog/#Added","page":"Changelog","title":"Added","text":"Implemented margin_error() ([#81]).\nAdded support for standard deviation weights for linear fits ([#80]).","category":"section"},{"location":"_changelog/#Changed","page":"Changelog","title":"Changed","text":"ScalarModel()'s will now operate in-place for improved performance ([#82]).","category":"section"},{"location":"_changelog/#[v1.3.0]-2026-01-26","page":"Changelog","title":"[v1.3.0] - 2026-01-26","text":"","category":"section"},{"location":"_changelog/#Added-2","page":"Changelog","title":"Added","text":"Added support for standard deviation weights for nonlinear fits ([#79]).","category":"section"},{"location":"_changelog/#Changed-2","page":"Changelog","title":"Changed","text":"Breaking: reinit!(::GenericNonlinearCurveFitCache) now takes in u0 as a keyword argument rather than a positional argument for consistency with NonlinearSolve.jl ([#79]).","category":"section"},{"location":"_changelog/#Fixed","page":"Changelog","title":"Fixed","text":"Fixed reinit!(::GenericNonlinearCurveFitCache) to allow passing a new x/y as well as u0 ([#79]).","category":"section"},{"location":"_changelog/#[v1.2.0]-2026-01-21","page":"Changelog","title":"[v1.2.0] - 2026-01-21","text":"","category":"section"},{"location":"_changelog/#Added-3","page":"Changelog","title":"Added","text":"Implemented ScalarModel to allow using scalar functions as models ([#75]).\nImplemented SciMLBase.successful_retcode() for CurveFitSolution ([#78]).","category":"section"},{"location":"changelog/#Changelog","page":"Changelog","title":"Changelog","text":"This documents notable changes in CurveFit.jl. The format is based on Keep a Changelog.","category":"section"},{"location":"changelog/#[v1.4.0](https://github.com/SciML/CurveFit.jl/releases/tag/v1.4.0)-2026-01-31","page":"Changelog","title":"v1.4.0 - 2026-01-31","text":"","category":"section"},{"location":"changelog/#Added","page":"Changelog","title":"Added","text":"Implemented margin_error() (#81).\nAdded support for standard deviation weights for linear fits (#80).","category":"section"},{"location":"changelog/#Changed","page":"Changelog","title":"Changed","text":"ScalarModel()'s will now operate in-place for improved performance (#82).","category":"section"},{"location":"changelog/#[v1.3.0](https://github.com/SciML/CurveFit.jl/releases/tag/v1.3.0)-2026-01-26","page":"Changelog","title":"v1.3.0 - 2026-01-26","text":"","category":"section"},{"location":"changelog/#Added-2","page":"Changelog","title":"Added","text":"Added support for standard deviation weights for nonlinear fits (#79).","category":"section"},{"location":"changelog/#Changed-2","page":"Changelog","title":"Changed","text":"Breaking: reinit!(::GenericNonlinearCurveFitCache) now takes in u0 as a keyword argument rather than a positional argument for consistency with NonlinearSolve.jl (#79).","category":"section"},{"location":"changelog/#Fixed","page":"Changelog","title":"Fixed","text":"Fixed reinit!(::GenericNonlinearCurveFitCache) to allow passing a new x/y as well as u0 (#79).","category":"section"},{"location":"changelog/#[v1.2.0](https://github.com/SciML/CurveFit.jl/releases/tag/v1.2.0)-2026-01-21","page":"Changelog","title":"v1.2.0 - 2026-01-21","text":"","category":"section"},{"location":"changelog/#Added-3","page":"Changelog","title":"Added","text":"Implemented ScalarModel to allow using scalar functions as models (#75).\nImplemented SciMLBase.successful_retcode() for CurveFitSolution (#78).","category":"section"},{"location":"tutorials/getting_started/#Getting-started-with-CurveFit.jl","page":"Getting started with CurveFit.jl","title":"Getting started with CurveFit.jl","text":"This tutorial introduces the basic workflow of CurveFit by walking through several simple examples. ","category":"section"},{"location":"tutorials/getting_started/#Linear-Fitting","page":"Getting started with CurveFit.jl","title":"Linear Fitting","text":"Fit a linear function y = a * x + b:\n\nusing CurveFit\n\n# Generate sample data: y = 2.5 * x + 3.0\nx = collect(0:0.1:10)\ny = @. 2.5 * x + 3.0\n\n# Create the problem and solve\nprob = CurveFitProblem(x, y)\nsol = solve(prob, LinearCurveFitAlgorithm())\n\n# Access the coefficients: sol.u = (a, b)\nprintln(\"Slope (a): \", sol.u[1])\nprintln(\"Intercept (b): \", sol.u[2])\n\n# Evaluate the solution at a point\nprintln(\"Prediction at x=5: \", sol(5.0))","category":"section"},{"location":"tutorials/getting_started/#Nonlinear-Curve-Fitting","page":"Getting started with CurveFit.jl","title":"Nonlinear Curve Fitting","text":"For arbitrary nonlinear functions, use NonlinearCurveFitProblem:\n\nusing CurveFit\n\n# Define a nonlinear function: y = a[1] + a[2] * x^a[3]\nfn(a, x) = @. a[1] + a[2] * x^a[3]\n\n# True parameters\ntrue_params = [3.0, 2.0, 0.7]\n\n# Generate sample data\nx = collect(1.0:0.5:10.0)\ny = fn(true_params, x)\n\n# Create problem with initial guess for parameters\nu0 = [0.5, 0.5, 0.5]\nprob = NonlinearCurveFitProblem(fn, u0, x, y)\nsol = solve(prob)\n\nprintln(\"Fitted parameters: \", sol.u)\nprintln(\"Prediction at x=5: \", sol(5.0))","category":"section"},{"location":"tutorials/getting_started/#Using-ScalarModel-for-Scalar-Functions","page":"Getting started with CurveFit.jl","title":"Using ScalarModel for Scalar Functions","text":"The @. macro in the example above broadcasts the function over all data points. If you prefer to define a simpler scalar function that operates on one data point at a time, use ScalarModel:\n\nusing CurveFit\n\n# Define a scalar function (no @. needed): y = a[1] + a[2] * x^a[3]\nfn_scalar(a, x) = a[1] + a[2] * x^a[3]\n\n# True parameters\ntrue_params = [3.0, 2.0, 0.7]\n\n# Generate sample data\nx = collect(1.0:0.5:10.0)\ny = fn_scalar.(Ref(true_params), x)  # Note: we still need to broadcast for data generation\n\n# Create problem with ScalarModel wrapper\nu0 = [0.5, 0.5, 0.5]\nprob = NonlinearCurveFitProblem(ScalarModel(fn_scalar), u0, x, y)\nsol = solve(prob)\n\nprintln(\"Fitted parameters: \", sol.u)\nprintln(\"Prediction at x=5: \", sol(5.0))","category":"section"},{"location":"tutorials/getting_started/#Migration-from-LsqFit.jl","page":"Getting started with CurveFit.jl","title":"Migration from LsqFit.jl","text":"If you're migrating from LsqFit.jl, note these key differences:\n\nParameter order is reversed: LsqFit uses model(x, p), CurveFit uses model(p, x).\nVectorized functions: CurveFit expects functions that operate on array data. Using ScalarModel makes migration easier.","category":"section"},{"location":"tutorials/getting_started/#Polynomial-Fitting","page":"Getting started with CurveFit.jl","title":"Polynomial Fitting","text":"Fit a polynomial of a given degree:\n\nusing CurveFit\n\n# Generate sample data: y = 1.0 + 2.0*x + 3.0*x^2\nx = collect(range(1, stop=10, length=20))\ny = @. 1.0 + 2.0 * x + 3.0 * x^2\n\n# Create the problem and solve with degree 2 polynomial\nprob = CurveFitProblem(x, y)\nsol = solve(prob, PolynomialFitAlgorithm(degree=2))\n\n# Access the coefficients: [c0, c1, c2] for c0 + c1*x + c2*x^2\nprintln(\"Coefficients: \", sol.u)\n\n# Evaluate the solution at a point\nprintln(\"Prediction at x=5: \", sol(5.0))","category":"section"},{"location":"tutorials/getting_started/#Exponential-Fitting","page":"Getting started with CurveFit.jl","title":"Exponential Fitting","text":"Fit an exponential function y = b * exp(a * x):\n\nusing CurveFit\n\n# Generate sample data: y = 2.0 * exp(0.3 * x)\nx = collect(range(0, stop=5, length=20))\ny = @. 2.0 * exp(0.3 * x)\n\nprob = CurveFitProblem(x, y)\nsol = solve(prob, ExpCurveFitAlgorithm())\n\n# sol.u[1] = a (exponent coefficient)\n# sol.u[2] = log(b)\nprintln(\"Exponent coefficient (a): \", sol.u[1])\nprintln(\"Scale factor (b): \", exp(sol.u[2]))","category":"section"},{"location":"tutorials/getting_started/#Power-Law-Fitting","page":"Getting started with CurveFit.jl","title":"Power Law Fitting","text":"Fit a power law y = b * x^a:\n\nusing CurveFit\n\n# Generate sample data: y = 2.0 * x^0.8\nx = collect(range(1, stop=10, length=20))\ny = @. 2.0 * x^0.8\n\nprob = CurveFitProblem(x, y)\nsol = solve(prob, PowerCurveFitAlgorithm())\n\n# sol.u[1] = a (exponent)\n# sol.u[2] = log(b)\nprintln(\"Exponent (a): \", sol.u[1])\nprintln(\"Scale factor (b): \", exp(sol.u[2]))","category":"section"},{"location":"tutorials/getting_started/#Sum-of-Exponentials","page":"Getting started with CurveFit.jl","title":"Sum of Exponentials","text":"Fit a sum of exponentials: y = k + p * exp(λ * t):\n\nusing CurveFit\n\n# Generate sample data: y = 2.0 + 3.0*exp(-0.5*t)\nt = collect(range(0, stop=10, length=50))\ny = @. 2.0 + 3.0 * exp(-0.5 * t)\n\nprob = CurveFitProblem(t, y)\nsol = solve(prob, ExpSumFitAlgorithm(n=1, withconst=true))\n\n# Access fitted parameters (returned as arrays for n exponentials)\n# k[] extracts the scalar from a 1-element array\nprintln(\"Constant (k): \", sol.u.k[])\nprintln(\"Amplitude (p): \", sol.u.p[])\nprintln(\"Decay rate (λ): \", sol.u.λ[])","category":"section"},{"location":"tutorials/getting_started/#Modified-King-fitting","page":"Getting started with CurveFit.jl","title":"Modified King fitting","text":"Fit with the modified king law: x^2 = a + b * y^n\n\nusing CurveFit\n\n# Generate the data: x^2 = a + b * y^n\nx = collect(10.0:20.0)\nθ_ref = [5.0, 1.3, 2.5]\ny = @. ((x^2 - θ_ref[2])/θ_ref[3])^(1/θ_ref[1])\n\n# Works with and without an initial guess\nprob = CurveFitProblem(x, y)\nsol = solve(prob, ModifiedKingCurveFitAlgorithm())\n\nprintln(\"Fitted parameters: \", sol.u)","category":"section"},{"location":"tutorials/getting_started/#Rational-polynomial-fitting","page":"Getting started with CurveFit.jl","title":"Rational polynomial fitting","text":"Fit a rational function: y = p(x)/q(x)\n\nusing CurveFit\n\n# Generate sample data: y = (1 + 2*x) / (1 + 0.5*x - 0.1*x^2)\nx = collect(range(0, stop=5, length=30))\ny = @. (1.0 + 2.0*x) / (1.0 + 0.5*x - 0.1*x^2)\n\n# Create the problem and solve with numerator degree 1, denominator degree 2\nprob = CurveFitProblem(x, y)\nalg = RationalPolynomialFitAlgorithm(num_degree=1, den_degree=2)\nsol = solve(prob, alg)\n\n# Access fitted coefficients\n# Numerator: p0 + p1*x\nprintln(\"Numerator coefficients: \", sol.u[1:2])\n# Denominator: 1 + q1*x + q2*x^2\nprintln(\"Denominator coefficients: \", vcat(1.0, sol.u[3:4]))\n\n# Evaluate the solution at a point\nprintln(\"Prediction at x=2: \", sol(2.0))","category":"section"},{"location":"api/solutions/#Solutions","page":"Solutions","title":"Solutions","text":"Curve fitting results are returned as CurveFitSolution objects. These objects store the fitted coefficients, residuals, the problem solved and the algorithm used to solve it. It also stores a return code which holds information about the success of the solver. For more information on the ReturnCode type, see SciMLBase.jl.","category":"section"},{"location":"api/solutions/#StatsAPI-functions","page":"Solutions","title":"StatsAPI functions","text":"CurveFitSolution objects can be treated as statistical models and CurveFit defines various statistics methods for the CurveFitSolution type, many of which extend StatsAPI.jl functions.","category":"section"},{"location":"api/solutions/#CurveFit.CurveFitSolution","page":"Solutions","title":"CurveFit.CurveFitSolution","text":"CurveFitSolution(alg, coeffs, resid, prob, retcode, original=nothing)\n\nRepresents the solution to a curve fitting problem. This is a callable struct and can be used to evaluate the solution at a point. Exact evaluation mechanism depends on the algorithm used to solve the problem.\n\n\n\n\n\n","category":"type"},{"location":"api/solutions/#StatsAPI.residuals","page":"Solutions","title":"StatsAPI.residuals","text":"residuals(sol::CurveFitSolution)\n\nReturn the residuals of the fitted model.\n\nResiduals are defined as the difference between the observed data and the model predictions evaluated at the fitted coefficients.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#CurveFit.mse","page":"Solutions","title":"CurveFit.mse","text":"mse(sol::CurveFitSolution)\n\nReturn the mean squared error of the fit.\n\nThe mean squared error is computed as rss(sol) / dof_residual(sol).\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.dof","page":"Solutions","title":"StatsAPI.dof","text":"dof(sol::CurveFitSolution)\n\nReturn the number of degrees of freedom of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.dof_residual","page":"Solutions","title":"StatsAPI.dof_residual","text":"dof_residual(sol::CurveFitSolution)\n\nReturn the residual degrees of freedom.\n\nThis is defined as nobs(sol) - dof(sol).\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.predict","page":"Solutions","title":"StatsAPI.predict","text":"predict(sol::CurveFitSolution, x = sol.prob.x)\n\nEvaluate the fitted model with new data.\n\nIf x is not provided, predictions are returned at the original data points used during fitting.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.coef","page":"Solutions","title":"StatsAPI.coef","text":"coef(sol::CurveFitSolution)\n\nReturn the fitted coefficients.\n\nThe ordering of coefficients depends on the fitting algorithm used.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.nobs","page":"Solutions","title":"StatsAPI.nobs","text":"nobs(sol::CurveFitSolution)\n\nReturn the number of observations used in the fit.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.fitted","page":"Solutions","title":"StatsAPI.fitted","text":"fitted(sol::CurveFitSolution)\n\nReturn the fitted values at the original data points.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.rss","page":"Solutions","title":"StatsAPI.rss","text":"rss(sol::CurveFitSolution)\n\nReturn the residual sum of squares (RSS).\n\nThis is defined as sum(abs2, residuals(sol)).\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#CurveFit.isconverged","page":"Solutions","title":"CurveFit.isconverged","text":"isconverged(sol::CurveFitSolution)\n\nReturn true if the underlying solver successfully converged.\n\nThis is determined from the solver return code.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.vcov","page":"Solutions","title":"StatsAPI.vcov","text":"vcov(sol::CurveFitSolution)\n\nReturn the variance–covariance matrix of the fitted coefficients.\n\nThe covariance matrix is computed using the Jacobian of the fitted model and a QR-based least squares formulation. This function is defined for solutions to both linear and nonlinear problems.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.stderror","page":"Solutions","title":"StatsAPI.stderror","text":"stderror(sol::CurveFitSolution; rtol = NaN, atol = 0)\n\nReturn the standard errors of the fitted coefficients.\n\nStandard errors are computed as the square roots of the diagonal elements of the variance–covariance matrix.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#CurveFit.margin_error","page":"Solutions","title":"CurveFit.margin_error","text":"margin_error(sol::CurveFitSolution, alpha = 0.05; rtol::Real = NaN, atol::Real = 0)\n\nReturns the margin of error of the fitted coefficients, computed as stderror(sol) * t where t is the critical value of the t-distribution for `1\n\nalpha / 2`.\n\n\n\n\n\n","category":"function"},{"location":"api/solutions/#StatsAPI.confint","page":"Solutions","title":"StatsAPI.confint","text":"confint(sol::CurveFitSolution; level = 0.95, rtol = NaN, atol = 0)\n\nReturn confidence intervals for the fitted parameters.\n\nThe confidence intervals are returned as a vector of (lower, upper) tuples, computed as coef(sol) ± margin_error(sol).\n\n\n\n\n\n","category":"function"},{"location":"#CurveFit.jl","page":"Home","title":"CurveFit.jl","text":"CurveFit provides a unified and extensible interface for linear, nonlinear, and specialized curve fitting in Julia. It offers built-in solvers for common linear and special-function models, while general nonlinear curve fitting is handled through nonlinear least squares methods from NonlinearSolve.jl.\n\nCurve fitting problems are defined in a consistent problem–solver style, allowing flexible solver selection and access to common statistical diagnostics such as residuals, standard errors, and confidence intervals via the StatsAPI.jl interface.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add(\"CurveFit\")","category":"section"},{"location":"#Quick-start","page":"Home","title":"Quick start","text":"using CurveFit\n\n# Sample data\nx = 0:0.1:10\ny = @. 2x + 1\n\n# Create and solve the problem\nprob = CurveFitProblem(x, y)\nsol = solve(prob, LinearCurveFitAlgorithm())\n\n# Check the fitted coefficients\nprintln(\"Slope (a): \", sol.u[1])\nprintln(\"Intercept (b): \", sol.u[2])\n\n# Make predictions\nprintln(\"Prediction at x=5: \", sol(5.0))\n\nSee Getting started for more step-by-step examples with common fits.","category":"section"},{"location":"tutorials/linsolve_choice/#Advanced-usage","page":"Advanced usage","title":"Advanced usage","text":"This tutorial covers advanced options for improving curve fitting performance by controlling the linear solvers used internally by nonlinear algorithms. It is intended for users who want more control over numerical stability, performance, or problem structure. NonlinearSolve.jl provides the user with the option to choose the linear solver they want for the Levenberg-Marquardt algorithm.","category":"section"},{"location":"tutorials/linsolve_choice/#Why-does-linear-solver-choice-matter","page":"Advanced usage","title":"Why does linear solver choice matter","text":"The Levenberg–Marquardt algorithm works by repeatedly solving linear systems involving the Jacobian matrix. At each iteration, systems of the form:\n\n(J^T cdot J + lambda cdot I)delta = J^T cdot r\n\nmust be solved. J is the Jacobian matrix and r the residual vector.\n\nThe numerical properties of these systems depend strongly on the structure and conditioning of the Jacobian. While NonlinearSolve.jl selects a reasonable default, explicitly choosing a linear solver can significantly improve robustness or performance in some cases.\n\nInside the LevenbergMarquardt constructor the keyword argument linsolve specifies the linear solver used in the algorithm. By default it is set to nothing and in that case NonlinearSolve.jl will choose a linear solver on its own. Users can pass their desired linear solver to the constructor in which case that will be the one used. Below is a simple example of how to pass a specific linear solver.","category":"section"},{"location":"tutorials/linsolve_choice/#Example","page":"Advanced usage","title":"Example","text":"using CurveFit\nusing NonlinearSolve\n\nX = collect(1.0:10.0)\nθ_true = [3.0, 1.5, 0.5]\n\nfunction f(θ, X)\n    return @. θ[1] + θ[2] * exp(θ[3] * X)\nend\nY = f(θ_true, X)\n\nnonf = NonlinearFunction(f)\nalg = LevenbergMarquardt(linsolve = QRFactorization())\n\nprob = NonlinearCurveFitProblem(nonf, [2.1, 3.3, 0.1], X, Y)\nsol = solve(prob, alg)","category":"section"},{"location":"tutorials/linsolve_choice/#Choosing-the-right-solver","page":"Advanced usage","title":"Choosing the right solver","text":"As a general guideline:\n\nQR-based factorization is recommended for ill-conditioned or rank-deficient problems. It is robust and numerically-stable. Slower than Cholesky factorization.\nCholesky-based factorization is efficient for well-conditioned problems and for symmetric positive definite matrices. Faster than qr factorization, but can be unstable.\nLU-based factorization falls somewhere in between QR and Cholesky factorization. Can be used, although the other two are usually better.\nThe default solver is usually a decent choice, unless some structural information about the problem is known which can be exploited.","category":"section"},{"location":"tutorials/linsolve_choice/#When-to-customize","page":"Advanced usage","title":"When to customize","text":"Custom solver selection is most useful when:\n\nFits fail to converge due to numerical instability\nJacobians are poorly conditioned\nProblem structure (dense, sparse, symmetric) is known in advance\nPerformance becomes critical for large problems\n\nIn most cases, the default choice is more than enough, but advanced users can benefit from this additional level of control.\n\nFor more detail see:\n\nLinearSolve.jl\nNonlinearSolve.jl","category":"section"},{"location":"api/solvers/#Solvers","page":"Solvers","title":"Solvers","text":"CurveFit provides built-in solvers for linear curve fitting problems. Nonlinear problems are delegated to NonlinearSolve.jl. In addition, CurveFit includes specialized algorithms for selected nonstandard models.","category":"section"},{"location":"api/solvers/#Linear-fitting","page":"Solvers","title":"Linear fitting","text":"Linear curve fitting in CurveFit solves problems of the general form f_y(y) = a cdot f_x(x) + b where x and y are the data points being fitted and a and b are the fit parameters.\n\nLinear fits do not require an initial guess. The user must explicitly select a linear algorithm, as no default is assumed.\n\nLinear fitting algorithms are represented by the LinearCurveFitAlgorithm type, which encapsulates transformations applied to the input and output data. The fields xfun and yfun define transformations applied to x and y, respectively, while yfun_inverse maps fitted parameters back to the original data space.\n\nThe default constructor corresponds to the standard linear model $ y = a \\cdot x + b $ where both transformations are identity functions. Users may supply custom transformations to define alternative linear relationships. The inverse transformation is computed using InverseFunctions.jl.\n\nThese are the convenience constructors exported by CurveFit used for defining some linear curve fitting algorithms:","category":"section"},{"location":"api/solvers/#Nonlinear-fitting","page":"Solvers","title":"Nonlinear fitting","text":"Nonlinear curve fitting problems are solved through NonlinearSolve.jl. The user defines  a nonlinear problem using NonlinearCurveFitProblem, supplying a model function and an  initial guess for the parameters.\n\nDuring initialization, CurveFit detects nonlinear problems by checking if a model function is provided and internally constructs a NonlinearLeastSquaresProblem, which is then passed  to NonlinearSolve.jl for solution. For details, see the documentation for NonlinearLeastSquaresProblem.\n\nBy default, NonlinearSolve.jl automatically selects an appropriate nonlinear least-squares algorithm. Advanced users may explicitly specify a solver, such as LevenbergMarquardt or GaussNewton. Documentation for available solvers can be found here.\n\nFor more details, see Advanced usage.","category":"section"},{"location":"api/solvers/#Special-functions","page":"Solvers","title":"Special functions","text":"CurveFit provides specialized algorithms for fitting selected classes of nonlinear models with known structure. These algorithms exploit problem-specific properties to improve robustness and performance compared to fully generic nonlinear least-squares approaches.","category":"section"},{"location":"api/solvers/#Modified-King-fitting","page":"Solvers","title":"Modified King fitting","text":"The Modified King fit algorithm is designed for the model function of the form:\n\nx^2 = a + b cdot y^n\n\nUnlike the linear King fit where the exponent is a constant (1/2), n in the exponent is  a coefficient and thus the problem becomes nonlinear. Since it is nonlinear solving it is done via NonlinearSolve.jl. This Modified King fit has a defined model and if the user tries  to solve a problem with a specified model function using this algorithm an error will be thrown. However, the user can pass an initial guess for the coefficients a, b and n. In case an initial guess is not provided CurveFit will obtain it internally by using the related linear King fit.","category":"section"},{"location":"api/solvers/#Sum-of-exponentials-fitting","page":"Solvers","title":"Sum of exponentials fitting","text":"The sum of exponentials fitting algorithm is defined for models of the form:\n\ny = k + sum_i=1^n p_i exp(lambda_i x)\n\nThe number of exponential terms is specified by the user. This method exploits the algebraic  structure of exponential sums to avoid solving a nonlinear problem. By computing discrete  cumulative integrals of the data, the problem is transformed into a linear recurrence  whose coefficients can be estimated using linear least squares. The exponential rates  (\\lambda_i) are then recovered as eigenvalues of a matrix derived from this recurrence.\n\nOnce the rates are known, the amplitudes (p_i) and the optional constant term (k) are obtained by solving a linear least squares problem with fixed exponential basis functions.\n\nFor more details see here.","category":"section"},{"location":"api/solvers/#Polynomial-fitting","page":"Solvers","title":"Polynomial fitting","text":"","category":"section"},{"location":"api/solvers/#Standard","page":"Solvers","title":"Standard","text":"Polynomial fitting solves problems of the form\n\ny = sum_k=0^n a_k x^k\n\nThe polynomial degree is specified by the user. The problem is formulated as  a LinearProblem using a Vandermonde matrix constructed from the input data The polynomial coefficients are obtained by solving this linear system with a user-selectable linear solver. \n\nPolynomial fitting is only applicable to linear curve fitting problems and does not support user-provided initial guesses. It is recommended to use numerically stable solvers such as QR-based factorizations. CurveFit allows the linear solver to be customized via the linsolve_algorithm field of PolynomialFitAlgorithm.","category":"section"},{"location":"api/solvers/#Rational","page":"Solvers","title":"Rational","text":"Rational polynomial fitting solves problems of the form\n\ny = fracp(x)q(x)\n\n(p(x)) and (q(x)) are polynomials of user-specified degrees. The constant term of the denominator is assumed to be 1. Rational polynomial fitting implements both linear and nonlinear methods. RationalPolynomialFitAlgorithm has three fields,  the first two are degrees of the numerator and denominator and third is the alg field which contains the algorithm used for solving the problem.\n\nIn case the user chooses a linear fit algorithm initial guesses are not supported. The problem is transformed into y cdot q(x) = p(x). This linearized problem is then solved by creating linear fit cache with LinearProblem which is then handled by the internal solver for linear rational fit of CurveFit. For more detail on Linear problem see.\n\nIf the user chooses a nonlinear algorithm, then the problem is solved via NonlinearSolve.jl. In this case the user can provide an initial guess. If it is not provided, then CurveFit will obtain one from the linear rational fit.","category":"section"},{"location":"api/solvers/#CurveFit.LinearCurveFitAlgorithm","page":"Solvers","title":"CurveFit.LinearCurveFitAlgorithm","text":"LinearCurveFitAlgorithm(;\n    xfun = identity, yfun = identity, yfun_inverse = inverse(yfun)\n)\n\nRepresents a linear curve fitting algorithm where x and y are the data points to fit. If the CurveFitProblem being solved has a sigma then it will be used as weights. We want to solve for a and b such that:\n\nf_y(y) = a f_x(x) + b\n\nwhere f_x corresponds to xfun and f_y corresponds to yfun. Note that this is a general problem specification of a curve fitting problem which can be converted to a linear fit in a specific function space by choosing appropriate xfun and yfun. The yfun_inverse is used to convert the fitted values back to the original space (can be specified by defining InverseFunctions.inverse).\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#CurveFit.LogCurveFitAlgorithm","page":"Solvers","title":"CurveFit.LogCurveFitAlgorithm","text":"LogCurveFitAlgorithm()\n\nRepresents a log curve fitting algorithm where x and y are the data points to fit. If the CurveFitProblem being solved has a sigma then it will be used as weights. We want to solve for a and b such that:\n\ny = a log(x) + b\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#CurveFit.PowerCurveFitAlgorithm","page":"Solvers","title":"CurveFit.PowerCurveFitAlgorithm","text":"PowerCurveFitAlgorithm()\n\nRepresents a power curve fitting algorithm where x and y are the data points to fit. This algorithm does not support passing weights through sigma in CurveFitProblem. We want to solve for a and b such that:\n\ny = b x^a\n\nThis is equivalent to a linear fit in log-log space, i.e.,\n\nlog(y) = a log(x) + log(b)\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#CurveFit.ExpCurveFitAlgorithm","page":"Solvers","title":"CurveFit.ExpCurveFitAlgorithm","text":"ExpCurveFitAlgorithm()\n\nRepresents an exponential curve fitting algorithm where x and y are the data points to fit. This algorithm does not support passing weights through sigma in CurveFitProblem. We want to solve for a and b such that:\n\ny = b exp(a x)\n\nThis is equivalent to a linear fit in log-linear space, i.e.,\n\nlog(y) = a x + log(b)\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#CurveFit.KingCurveFitAlgorithm","page":"Solvers","title":"CurveFit.KingCurveFitAlgorithm","text":"KingCurveFitAlgorithm()\n\nRepresents a king curve fitting problem where x and y are the data points to fit. This algorithm does not support passing weights through sigma in CurveFitProblem. We want to solve for a and b according to original King's law (1910) that represents the relationship between voltage (E) and velocity (U) in a hotwire anemometer:\n\nE^2 = A + B U^12\n\nor\n\nx^2 = A + B y^12\n\n\n\n\n\n","category":"function"},{"location":"api/solvers/#CurveFit.ModifiedKingCurveFitAlgorithm","page":"Solvers","title":"CurveFit.ModifiedKingCurveFitAlgorithm","text":"ModifiedKingCurveFitAlgorithm(alg::Union{Nothing, AbstractNonlinearAlgorithm} = nothing)\n\nSimilar to KingCurveFitAlgorithm, but uses the modified King's law:\n\nE^2 = A + B U^n\n\nwhere n is also a parameter.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#CurveFit.ExpSumFitAlgorithm","page":"Solvers","title":"CurveFit.ExpSumFitAlgorithm","text":"ExpSumFitAlgorithm(; n::Int, m::Int = 1, withconst::Bool = true)\n\nFits the sum of n exponentials and a constant. This algorithm does not support passing weights through sigma in CurveFitProblem.\n\ny = k + p_1 e^λ_1 t + p_2 e^λ_2 t +  + p_n e^λ_n t\n\nIf the keyword withconst is set to false, the constant is not fitted but set k=0.\n\nUses numerical integration with m strips, where the default m=1 uses linear interpolation. m=2 and higher require uniform interval and usually lead to better accuracy.\n\nThis algorithm is from Matlab code of Juan Gonzales Burgos.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#CurveFit.PolynomialFitAlgorithm","page":"Solvers","title":"CurveFit.PolynomialFitAlgorithm","text":"PolynomialFitAlgorithm(degree::Int)\nPolynomialFitAlgorithm(;\n    degree::Int,\n    linsolve_algorithm::Union{Nothing, AbstractLinearAlgorithm} = nothing\n)\n\nRepresents a polynomial fitting algorithm of degree degree. Only applicable to LinearCurveFitAlgorithms. This algorithm does not support passing weights through sigma in CurveFitProblem.\n\ntip: Tip\nFor ill-conditioned problems, it is recommended to use linear solvers like QRFactorization. Alternatively, pass in assumptions = OperatorAssumptions(false; condition = OperatorsCondition.<condition>) to solve/init.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#CurveFit.RationalPolynomialFitAlgorithm","page":"Solvers","title":"CurveFit.RationalPolynomialFitAlgorithm","text":"RationalPolynomialFitAlgorithm(num_degree::Int, den_degree::Int)\nRationalPolynomialFitAlgorithm(;\n    num_degree::Int, den_degree::Int, alg = nothing\n)\n\nRepresents a rational polynomial fitting algorithm with numerator degree num_degree and denominator degree den_degree. The internal polynomial fitting algorithm is determined by the alg keyword argument. If alg is nothing or a AbstractNonlinearAlgorithm (like solvers from NonlinearSolve.jl), it will use a nonlinear curve fitting approach. If alg is a AbstractLinearAlgorithm, it will use linear least squares fitting. This algorithm does not support passing weights through sigma in CurveFitProblem.\n\nLinear Rational Polynomial Fitting\n\nIn this case the following curve fit is done:\n\ny = fracp(x)q(x)\n\nwhere p(x) is a polynomial of degree num_degree and q(x) is a polynomial of degree den_degree. The linear case is solved by doing a least squares fit on:\n\ny q(x) = p(x)\n\nwhere the zero order term of q(x) is assumed to be 1.\n\nNonlinear Rational Polynomial Fitting\n\nIf an u0 is not provided to the problem, then we will use linear least squares for an initial guess.\n\n\n\n\n\n","category":"type"}]
}
